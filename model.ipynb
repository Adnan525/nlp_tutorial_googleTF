{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49bdd472-fb52-45be-b90f-39c1794a9f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bf6cae-ad3f-4350-85c0-b28c1f24fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-25 11:45:46--  https://storage.googleapis.com/learning-datasets/sarcasm.json\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.24.59, 2404:6800:4006:804::201b\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.24.59|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5643545 (5.4M) [application/json]\n",
      "Saving to: ‘/tmp/sarcasm.json’\n",
      "\n",
      "/tmp/sarcasm.json   100%[===================>]   5.38M  4.79MB/s    in 1.1s    \n",
      "\n",
      "2024-02-25 11:45:48 (4.79 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/learning-datasets/sarcasm.json \\\n",
    "    -O /tmp/sarcasm.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c467df9d-f36b-485b-805b-29c94d73bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/sarcasm.json\", \"r\") as f:\n",
    "    ds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddafc799-d0b0-494c-88da-1d2aa7a1f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "sentences = []\n",
    "labels = []\n",
    "urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32cc09f2-685c-455f-b47e-c0bf2c5b16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in ds:\n",
    "    sentences.append(entry[\"headline\"])\n",
    "    labels.append(entry[\"is_sarcastic\"])\n",
    "    urls.append(entry[\"article_link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530136db-723c-4693-83fd-0048de734e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26709\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d45171-4299-411c-bc9f-afaec47fa4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = sentences[0 : int(len(sentences) * 0.7)]\n",
    "train_y = labels[0 : int(len(sentences) * 0.7)]\n",
    "\n",
    "test_X = sentences[int(len(sentences) * 0.7) :]\n",
    "test_y = labels[int(len(sentences) * 0.7) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267efe6-c598-48c6-980a-9587317d687a",
   "metadata": {},
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3cd5820-bb8e-4797-a8cf-81afc21fd346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 11:45:59.753979: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-25 11:46:01.900881: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-25 11:46:01.900983: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-25 11:46:02.220150: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-25 11:46:02.914945: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-25 11:46:02.916323: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-25 11:46:06.550241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "210f738c-1116-4e89-8c6a-f54709b9f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "# tokenizer will have train words only\n",
    "tokenizer.fit_on_texts(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9bc46a-7c3c-4275-a585-d2051a336b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24791"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd762778-7d6b-47ab-a3da-917458064d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the tokenizer\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "# Convert the dictionary to a JSON-formatted string\n",
    "tokenizer_json_str = json.dumps(tokenizer_json)\n",
    "\n",
    "# Write the JSON-formatted string to the file\n",
    "with open(\"tokenizer.json\", \"w\") as json_file:\n",
    "    json_file.write(tokenizer_json_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2500d4d-c567-4eeb-949e-48a8d2fe6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "training_sequences = tokenizer.texts_to_sequences(train_X)\n",
    "training_padded_sequences = pad_sequences(training_sequences, padding  = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adadd73e-6c41-487e-bda9-63ae940255ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18696, 40)\n"
     ]
    }
   ],
   "source": [
    "print(training_padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4471c08-10c9-4632-9f56-f939d35f75c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18696\n"
     ]
    }
   ],
   "source": [
    "print(len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9190fb9-43fb-4316-9d80-d5ca70433dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "testing_sequences = tokenizer.texts_to_sequences(test_X)\n",
    "testing_padded_sequences = pad_sequences(testing_sequences, padding  = \"post\", maxlen = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5409fed-babe-4c70-9a1e-7d17d1365e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding and model\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc7b88d-f846-48d9-b60f-f9e5dfbf8131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 40, 16)            160000    \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 16)                0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 24)                408       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160433 (626.69 KB)\n",
      "Trainable params: 160433 (626.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Embedding layers's primary function is to map discrete categorical variables, such as word indices, to continuous vectors of fixed size\n",
    "# GlobalAveragePooling1D computes the average value over the entire sequence. For each feature map (channel), it computes the average value of all the elements along the sequence dimension.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16, input_length = len(training_padded_sequences[0])), # vocabulary size, outpput size/embedding size, input length\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2a8de2d-9eff-470c-b492-d5c55d39c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "585/585 - 2s - loss: 0.5862 - accuracy: 0.6753 - 2s/epoch - 3ms/step\n",
      "Epoch 2/30\n",
      "585/585 - 1s - loss: 0.3302 - accuracy: 0.8683 - 1s/epoch - 2ms/step\n",
      "Epoch 3/30\n",
      "585/585 - 1s - loss: 0.2455 - accuracy: 0.9042 - 1s/epoch - 2ms/step\n",
      "Epoch 4/30\n",
      "585/585 - 1s - loss: 0.1991 - accuracy: 0.9238 - 1s/epoch - 2ms/step\n",
      "Epoch 5/30\n",
      "585/585 - 1s - loss: 0.1639 - accuracy: 0.9404 - 1s/epoch - 2ms/step\n",
      "Epoch 6/30\n",
      "585/585 - 1s - loss: 0.1391 - accuracy: 0.9498 - 1s/epoch - 2ms/step\n",
      "Epoch 7/30\n",
      "585/585 - 1s - loss: 0.1193 - accuracy: 0.9590 - 1s/epoch - 2ms/step\n",
      "Epoch 8/30\n",
      "585/585 - 1s - loss: 0.1027 - accuracy: 0.9659 - 1s/epoch - 2ms/step\n",
      "Epoch 9/30\n",
      "585/585 - 1s - loss: 0.0894 - accuracy: 0.9703 - 1s/epoch - 2ms/step\n",
      "Epoch 10/30\n",
      "585/585 - 1s - loss: 0.0786 - accuracy: 0.9744 - 1s/epoch - 2ms/step\n",
      "Epoch 11/30\n",
      "585/585 - 1s - loss: 0.0699 - accuracy: 0.9790 - 1s/epoch - 2ms/step\n",
      "Epoch 12/30\n",
      "585/585 - 1s - loss: 0.0600 - accuracy: 0.9823 - 1s/epoch - 2ms/step\n",
      "Epoch 13/30\n",
      "585/585 - 1s - loss: 0.0520 - accuracy: 0.9851 - 1s/epoch - 2ms/step\n",
      "Epoch 14/30\n",
      "585/585 - 1s - loss: 0.0466 - accuracy: 0.9874 - 1s/epoch - 2ms/step\n",
      "Epoch 15/30\n",
      "585/585 - 1s - loss: 0.0419 - accuracy: 0.9888 - 1s/epoch - 2ms/step\n",
      "Epoch 16/30\n",
      "585/585 - 1s - loss: 0.0354 - accuracy: 0.9899 - 1s/epoch - 2ms/step\n",
      "Epoch 17/30\n",
      "585/585 - 1s - loss: 0.0325 - accuracy: 0.9914 - 1s/epoch - 2ms/step\n",
      "Epoch 18/30\n",
      "585/585 - 1s - loss: 0.0277 - accuracy: 0.9928 - 1s/epoch - 2ms/step\n",
      "Epoch 19/30\n",
      "585/585 - 1s - loss: 0.0250 - accuracy: 0.9936 - 1s/epoch - 2ms/step\n",
      "Epoch 20/30\n",
      "585/585 - 1s - loss: 0.0236 - accuracy: 0.9940 - 1s/epoch - 2ms/step\n",
      "Epoch 21/30\n",
      "585/585 - 1s - loss: 0.0200 - accuracy: 0.9956 - 1s/epoch - 2ms/step\n",
      "Epoch 22/30\n",
      "585/585 - 1s - loss: 0.0172 - accuracy: 0.9960 - 1s/epoch - 2ms/step\n",
      "Epoch 23/30\n",
      "585/585 - 1s - loss: 0.0160 - accuracy: 0.9957 - 1s/epoch - 2ms/step\n",
      "Epoch 24/30\n",
      "585/585 - 1s - loss: 0.0145 - accuracy: 0.9967 - 1s/epoch - 2ms/step\n",
      "Epoch 25/30\n",
      "585/585 - 1s - loss: 0.0128 - accuracy: 0.9971 - 1s/epoch - 2ms/step\n",
      "Epoch 26/30\n",
      "585/585 - 1s - loss: 0.0112 - accuracy: 0.9970 - 1s/epoch - 2ms/step\n",
      "Epoch 27/30\n",
      "585/585 - 1s - loss: 0.0110 - accuracy: 0.9974 - 1s/epoch - 2ms/step\n",
      "Epoch 28/30\n",
      "585/585 - 1s - loss: 0.0098 - accuracy: 0.9978 - 1s/epoch - 2ms/step\n",
      "Epoch 29/30\n",
      "585/585 - 1s - loss: 0.0091 - accuracy: 0.9979 - 1s/epoch - 2ms/step\n",
      "Epoch 30/30\n",
      "585/585 - 1s - loss: 0.0076 - accuracy: 0.9983 - 1s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history = model.fit(np.array(training_padded_sequences), np.array(train_y), epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ce122a9-a485-4bee-ae87-bbb759d530d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# saving the model\n",
    "model.save(\"sarcasm_detection.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97ceb12f-4c2d-496c-adfc-270b628c1eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 786us/step\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "y_pred = model.predict(testing_padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "029fdb16-c76a-40ea-993b-9d194fb31d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "binary_predictions = convert_to_binary(y_pred, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8c3b9dc-3af5-4f8e-b936-3dc04fefbae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7982029202545863"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(binary_predictions, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab355a0f-39e3-44a6-8be1-ff68bf35a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(y_pred, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Convert continuous predictions to binary using a threshold.\n",
    "\n",
    "    Args:\n",
    "    - y_pred (array-like): Continuous predictions.\n",
    "    - threshold (float): Threshold value for classification.\n",
    "\n",
    "    Returns:\n",
    "    - Binary predictions (array-like).\n",
    "    \"\"\"\n",
    "    return [1 if pred >= threshold else 0 for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f21f60-4376-4062-b126-51e31f78d810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
