{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49bdd472-fb52-45be-b90f-39c1794a9f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98bf6cae-ad3f-4350-85c0-b28c1f24fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-21 13:37:33--  https://storage.googleapis.com/learning-datasets/sarcasm.json\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.24.59, 2404:6800:4006:804::201b\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.24.59|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5643545 (5.4M) [application/json]\n",
      "Saving to: ‘/tmp/sarcasm.json’\n",
      "\n",
      "/tmp/sarcasm.json   100%[===================>]   5.38M  5.00MB/s    in 1.1s    \n",
      "\n",
      "2024-02-21 13:37:35 (5.00 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/learning-datasets/sarcasm.json \\\n",
    "    -O /tmp/sarcasm.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c467df9d-f36b-485b-805b-29c94d73bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/sarcasm.json\", \"r\") as f:\n",
    "    ds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddafc799-d0b0-494c-88da-1d2aa7a1f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "sentences = []\n",
    "labels = []\n",
    "urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "32cc09f2-685c-455f-b47e-c0bf2c5b16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in ds:\n",
    "    sentences.append(entry[\"headline\"])\n",
    "    labels.append(entry[\"is_sarcastic\"])\n",
    "    urls.append(entry[\"article_link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "530136db-723c-4693-83fd-0048de734e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26709\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "73d45171-4299-411c-bc9f-afaec47fa4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = sentences[0 : int(len(sentences) * 0.7)]\n",
    "train_y = labels[0 : int(len(sentences) * 0.7)]\n",
    "\n",
    "test_X = sentences[int(len(sentences) * 0.7) :]\n",
    "test_y = labels[int(len(sentences) * 0.7) :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267efe6-c598-48c6-980a-9587317d687a",
   "metadata": {},
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3cd5820-bb8e-4797-a8cf-81afc21fd346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "210f738c-1116-4e89-8c6a-f54709b9f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "# tokenizer will have train words only\n",
    "tokenizer.fit_on_texts(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d9bc46a-7c3c-4275-a585-d2051a336b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24791"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e2500d4d-c567-4eeb-949e-48a8d2fe6959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "training_sequences = tokenizer.texts_to_sequences(train_X)\n",
    "training_padded_sequences = pad_sequences(training_sequences, padding  = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "adadd73e-6c41-487e-bda9-63ae940255ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18696, 40)\n"
     ]
    }
   ],
   "source": [
    "print(training_padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4471c08-10c9-4632-9f56-f939d35f75c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18696\n"
     ]
    }
   ],
   "source": [
    "print(len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9190fb9-43fb-4316-9d80-d5ca70433dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "testing_sequences = tokenizer.texts_to_sequences(test_X)\n",
    "testing_padded_sequences = pad_sequences(testing_sequences, padding  = \"post\", maxlen = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f5409fed-babe-4c70-9a1e-7d17d1365e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding and model\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "acc7b88d-f846-48d9-b60f-f9e5dfbf8131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 40, 16)            160000    \n",
      "                                                                 \n",
      " global_average_pooling1d_5  (None, 16)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 24)                408       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160433 (626.69 KB)\n",
      "Trainable params: 160433 (626.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16, input_length = len(training_padded_sequences[0])), # vocabulary size, outpput size/embedding size, input length\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c2a8de2d-9eff-470c-b492-d5c55d39c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "585/585 - 1s - loss: 0.6008 - accuracy: 0.6693 - 1s/epoch - 2ms/step\n",
      "Epoch 2/30\n",
      "585/585 - 1s - loss: 0.3377 - accuracy: 0.8641 - 866ms/epoch - 1ms/step\n",
      "Epoch 3/30\n",
      "585/585 - 1s - loss: 0.2519 - accuracy: 0.8981 - 864ms/epoch - 1ms/step\n",
      "Epoch 4/30\n",
      "585/585 - 1s - loss: 0.2027 - accuracy: 0.9216 - 858ms/epoch - 1ms/step\n",
      "Epoch 5/30\n",
      "585/585 - 1s - loss: 0.1677 - accuracy: 0.9392 - 964ms/epoch - 2ms/step\n",
      "Epoch 6/30\n",
      "585/585 - 1s - loss: 0.1423 - accuracy: 0.9487 - 863ms/epoch - 1ms/step\n",
      "Epoch 7/30\n",
      "585/585 - 1s - loss: 0.1205 - accuracy: 0.9572 - 856ms/epoch - 1ms/step\n",
      "Epoch 8/30\n",
      "585/585 - 1s - loss: 0.1037 - accuracy: 0.9645 - 853ms/epoch - 1ms/step\n",
      "Epoch 9/30\n",
      "585/585 - 1s - loss: 0.0906 - accuracy: 0.9708 - 852ms/epoch - 1ms/step\n",
      "Epoch 10/30\n",
      "585/585 - 1s - loss: 0.0789 - accuracy: 0.9743 - 855ms/epoch - 1ms/step\n",
      "Epoch 11/30\n",
      "585/585 - 1s - loss: 0.0689 - accuracy: 0.9786 - 855ms/epoch - 1ms/step\n",
      "Epoch 12/30\n",
      "585/585 - 1s - loss: 0.0592 - accuracy: 0.9821 - 862ms/epoch - 1ms/step\n",
      "Epoch 13/30\n",
      "585/585 - 1s - loss: 0.0524 - accuracy: 0.9843 - 870ms/epoch - 1ms/step\n",
      "Epoch 14/30\n",
      "585/585 - 1s - loss: 0.0453 - accuracy: 0.9873 - 855ms/epoch - 1ms/step\n",
      "Epoch 15/30\n",
      "585/585 - 1s - loss: 0.0409 - accuracy: 0.9886 - 870ms/epoch - 1ms/step\n",
      "Epoch 16/30\n",
      "585/585 - 1s - loss: 0.0351 - accuracy: 0.9905 - 990ms/epoch - 2ms/step\n",
      "Epoch 17/30\n",
      "585/585 - 1s - loss: 0.0303 - accuracy: 0.9925 - 870ms/epoch - 1ms/step\n",
      "Epoch 18/30\n",
      "585/585 - 1s - loss: 0.0302 - accuracy: 0.9917 - 867ms/epoch - 1ms/step\n",
      "Epoch 19/30\n",
      "585/585 - 1s - loss: 0.0237 - accuracy: 0.9937 - 854ms/epoch - 1ms/step\n",
      "Epoch 20/30\n",
      "585/585 - 1s - loss: 0.0210 - accuracy: 0.9944 - 864ms/epoch - 1ms/step\n",
      "Epoch 21/30\n",
      "585/585 - 1s - loss: 0.0179 - accuracy: 0.9959 - 863ms/epoch - 1ms/step\n",
      "Epoch 22/30\n",
      "585/585 - 1s - loss: 0.0162 - accuracy: 0.9959 - 860ms/epoch - 1ms/step\n",
      "Epoch 23/30\n",
      "585/585 - 1s - loss: 0.0153 - accuracy: 0.9961 - 905ms/epoch - 2ms/step\n",
      "Epoch 24/30\n",
      "585/585 - 1s - loss: 0.0139 - accuracy: 0.9963 - 876ms/epoch - 1ms/step\n",
      "Epoch 25/30\n",
      "585/585 - 1s - loss: 0.0130 - accuracy: 0.9963 - 855ms/epoch - 1ms/step\n",
      "Epoch 26/30\n",
      "585/585 - 1s - loss: 0.0116 - accuracy: 0.9971 - 848ms/epoch - 1ms/step\n",
      "Epoch 27/30\n",
      "585/585 - 1s - loss: 0.0098 - accuracy: 0.9978 - 869ms/epoch - 1ms/step\n",
      "Epoch 28/30\n",
      "585/585 - 1s - loss: 0.0088 - accuracy: 0.9979 - 961ms/epoch - 2ms/step\n",
      "Epoch 29/30\n",
      "585/585 - 1s - loss: 0.0109 - accuracy: 0.9968 - 862ms/epoch - 1ms/step\n",
      "Epoch 30/30\n",
      "585/585 - 1s - loss: 0.0070 - accuracy: 0.9980 - 857ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history = model.fit(np.array(training_padded_sequences), np.array(train_y), epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "97ceb12f-4c2d-496c-adfc-270b628c1eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 0s 782us/step\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "y_pred = model.predict(testing_padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a8c3b9dc-3af5-4f8e-b936-3dc04fefbae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m----> 2\u001b[0m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:94\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     96\u001b[0m             type_true, type_pred\n\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    101\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f21f60-4376-4062-b126-51e31f78d810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
